{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - Využití neuronových sítí\n",
    "\n",
    "  * **Deadline je 13. 5. 2024, 23:59:59**, pokud odevzdáte úkol do 20. 5. 2024, 23:59:59, budete penalizování -12 body, pozdější odevzdání je bez bodu.\n",
    "  * V rámci tohoto úkolu musíte sestrojit vhodný model neuronové sítě pro vícetřídou klasifikaci.\n",
    "  * Část bodů získáte za správné vypracování a část bodů získáte za výslednou přesnost Vašeho modelu na evaluačních datech.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "Využívejte buňky typu `Markdown` k vysvětlování Vašeho postupu. Za nepřehlednost budou strhávány body.\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    " * Zdrojem dat jsou soubory `train.csv` a `evaluate.csv`.\n",
    " * Jedná se o obrázky 32x32 pixelů ve stupních šedi, které byly nějakým způsobem vyrobeny z [Fashion Mnist datasetu](https://www.kaggle.com/datasets/zalando-research/fashionmnist).\n",
    " * Soubor `train.csv` obsahuje trénovací data.\n",
    " * Cílová (vysvětlovaná) proměnná se jmenuje **label**.\n",
    " * Soubor `evaluate.csv` obsahuje testovací data bez hodnot skutečných labelů.\n",
    "\n",
    "## Pokyny k vypracování (max 18 bodů)\n",
    "\n",
    "**Body zadání**, za jejichž (poctivé) vypracování získáte **18 bodů**:\n",
    "  * V notebooku načtěte data ze souboru `train.csv`. Vhodným způsobem si je rozdělte na podmnožiny, které Vám poslouží pro trénování, porovnávání modelů a následnou predikci výkonnosti finálního modelu.\n",
    "  * Proveďte základní průzkum dat a svá pozorování diskutujte. Některé obrázky také zobrazte.\n",
    "  * Sestrojte a natrénujte několik variant modelu dopředné neuronové sítě. Přitom v rámci výpočetních možností:\n",
    "      * Okomentujte vhodnost daného modelu pro daný typ úlohy.\n",
    "      * Experimentujte s různými hloubkami a velikosmi vrstev.\n",
    "      * Experimentujte se standardizací/normalizací dat.\n",
    "      * Experimentujte s různými optimalizačními metodami.\n",
    "      * Experimentujte s různými regularizačními technikami.\n",
    "      * Získané výsledky vždy řádně okomentujte.\n",
    "\n",
    "  * Sestrojte model konvoluční neuronové sítě. Přitom v rámci výpočetních možností:\n",
    "      * Okomentujte vhodnost daného modelu pro daný typ úlohy.\n",
    "      * Experimentujte s různými hloubkami a velikosmi vrstev.\n",
    "      * Experimentujte se standardizací/normalizací dat.\n",
    "      * Experimentujte s různými optimalizačními metodami.\n",
    "      * Experimentujte s různými regularizačními technikami.\n",
    "      * Získané výsledky vždy řádně okomentujte.\n",
    "    \n",
    "  * Ze všech zkoušených možností vyberte finální model a odhadněte, jakou přesnost můžete očekávat na nových datech, která jste doposud neměli k dispozici.\n",
    "  \n",
    "  * Nakonec načtěte vyhodnocovací data ze souboru`evaluate.csv`. Pomocí finálního modelu napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte soubor `results.csv`, ve kterém získané predikce uložíte do sloupce **label** a identifikátory do sloupce **ID**. Tento soubor též odevzdejte (uložte do projektu vedle notebooku).\n",
    "   \n",
    "   * Ukázka prvních řádků souboru `results.csv`:\n",
    "  \n",
    "```\n",
    "ID,label\n",
    "0,0\n",
    "1,1\n",
    "...\n",
    "```\n",
    "\n",
    "## Vyhodnocovací část (max 7 bodů)\n",
    "Za přesnost (accuraccy) na odevzdaných predikcích pro vyhodnocovací množnu získáte dalších max **7 bodů**.\n",
    "\n",
    "Označíme-li $A$ přesnost, které jste dosáhli, zaokrouhlenou na 2 desetinná místa, akumulují se výsledné body podle následujících pravidel:\n",
    "* pokud $A \\geq 0.80$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.83$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.86$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.87$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.88$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.89$ obdržíte +1 bod\n",
    "* pokud $A \\geq 0.90$ obdržíte +1 bod\n",
    "\n",
    "**Příklad:** Pokud bude Vaše přesnost 0.856, vyjde A = 0.86 a vy získáte 3 body.\n",
    "\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-ML2/homeworks/index.html.\n",
    "  * Vytvořte i csv soubor `results.csv` s predikcemi a uložte ho v rámci projektu vedle ipython notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### odtud už je to Vaše\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import colormaps\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #use gpu if cuda is available, otherwise use cpu \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data and process data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pix1  pix2  pix3  pix4  pix5  pix6  pix7  pix8  pix9  pix10  ...  pix1016  \\\n",
      "0     0     0     0     0     0     0     0     0     0      0  ...        0   \n",
      "1     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
      "2     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
      "3     0     0     0     0     0     0     0     0     0      0  ...        0   \n",
      "4     1     1     1     1     1     1     1     1     1      1  ...        1   \n",
      "\n",
      "   pix1017  pix1018  pix1019  pix1020  pix1021  pix1022  pix1023  pix1024  \\\n",
      "0        0        0        0        0        0        0        0        0   \n",
      "1        1        1        1        1        1        1        1        1   \n",
      "2        1        1        1        1        1        1        1        1   \n",
      "3        0        0        0        0        0        0        0        0   \n",
      "4        1        1        1        1        1        1        1        1   \n",
      "\n",
      "   label  \n",
      "0      3  \n",
      "1      3  \n",
      "2      7  \n",
      "3      9  \n",
      "4      5  \n",
      "\n",
      "[5 rows x 1025 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('train.csv')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset.label\n",
    "data = dataset.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create data and target value tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tensor = torch.tensor(targets.values, device=device , dtype = torch.long)\n",
    "data_tensor_norm = torch.tensor(data.values, dtype=torch.float, device=device) / 255.0  # Normalize pixel values to range [0, 1]\n",
    "data_tensor = torch.tensor(data.values, dtype=torch.float, device=device)  # With no normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 3, 7,  ..., 9, 6, 3], device='cuda:0')\n",
      "unnormalized tenzor is: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [4., 4., 4.,  ..., 4., 4., 4.]], device='cuda:0')\n",
      "normalized tenzor is: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(labels_tensor)\n",
    "print (\"unnormalized tenzor is:\",data_tensor)\n",
    "print (\"normalized tenzor is:\",data_tensor_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset's size is : 52500\n"
     ]
    }
   ],
   "source": [
    "tensor_dataset = torch.utils.data.TensorDataset(data_tensor, labels_tensor)\n",
    "tensor_dataset_norm = torch.utils.data.TensorDataset(data_tensor_norm, labels_tensor)\n",
    "\n",
    "print(f\"Dataset's size is : {len(tensor_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data on train, val and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train data is: 31500\n",
      "The length of val data is: 10500\n",
      "The length of test data is: 10500\n"
     ]
    }
   ],
   "source": [
    "generator1 = torch.Generator().manual_seed(666)\n",
    "train_data, test_data = torch.utils.data.random_split(tensor_dataset, [0.6, 0.4], generator1)\n",
    "val_data, test_data = torch.utils.data.random_split(test_data, [0.5, 0.5], generator1)\n",
    "\n",
    "train_data_norm, test_data_norm = torch.utils.data.random_split(tensor_dataset_norm, [0.6, 0.4], generator1)\n",
    "val_data_norm, test_data_norm = torch.utils.data.random_split(test_data_norm, [0.5, 0.5], generator1)\n",
    "print(\"The length of train data is:\",len(train_data))\n",
    "print(\"The length of val data is:\",len(val_data))\n",
    "print(\"The length of test data is:\",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research some info about given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "5    5300\n",
      "9    5275\n",
      "8    5274\n",
      "3    5266\n",
      "7    5258\n",
      "0    5253\n",
      "6    5244\n",
      "4    5225\n",
      "2    5222\n",
      "1    5183\n",
      "Name: count, dtype: int64\n",
      "0        1024\n",
      "1        1024\n",
      "2        1024\n",
      "3        1024\n",
      "4        1024\n",
      "         ... \n",
      "52495    1024\n",
      "52496    1024\n",
      "52497    1024\n",
      "52498    1024\n",
      "52499    1024\n",
      "Length: 52500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#As we can see, the label may be in the interval between 0 and 9 as it's value and the count of each value is generally even\n",
    "print( targets.value_counts() )\n",
    "#There're 52500 images 32*32 pixels\n",
    "print( data.count(axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show examples of some images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_rows = data.sample(n=5)\n",
    "\n",
    "for index, row in random_rows.iterrows():\n",
    "    row_data = row.values\n",
    "\n",
    "    image = np.array(row_data).reshape(32, 32)\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.title(f\"Label {targets[index]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a Feedforward neural network\n",
    "\n",
    "First create data loaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(val_data, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False)\n",
    "training_loader_norm = torch.utils.data.DataLoader(train_data_norm, batch_size=32, shuffle=True)\n",
    "validation_loader_norm = torch.utils.data.DataLoader(val_data_norm, batch_size=128, shuffle=False)\n",
    "test_loader_norm = torch.utils.data.DataLoader(test_data_norm, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1024])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images, labels\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural network class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "        def __init__(self,hidden_layer_size, num_hidden_layers):\n",
    "            super(MyNet, self).__init__()\n",
    "            self.num_hidden_layers = num_hidden_layers\n",
    "            self.layers = nn.ModuleList()\n",
    "            #input layer\n",
    "            self.layers.append(nn.Linear(1024, hidden_layer_size))\n",
    "            # hidden layers\n",
    "            for _ in range(num_hidden_layers):\n",
    "                self.layers.append(nn.Linear(hidden_layer_size, hidden_layer_size))\n",
    "            #output layer\n",
    "            self.layers.append(nn.Linear(hidden_layer_size, 10))\n",
    "\n",
    "        def forward(self, x):\n",
    "            for i in range (self.num_hidden_layers):\n",
    "                x = F.relu(self.layers[i](x))\n",
    "            x = self.layers[self.num_hidden_layers](x)\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer, training_loader, device):\n",
    "    running_cum_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  # Move data to device\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs.shape, labels.shape)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        last_mean_loss = loss.item()\n",
    "        running_cum_loss += last_mean_loss * inputs.shape[0]\n",
    "        # if i % 300 == 299:\n",
    "        #     print(f\"  Batch {i+1}, Loss: {last_mean_loss:.3f}\")\n",
    "            \n",
    "    # Return average loss over the whole training set\n",
    "    return running_cum_loss / len(training_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934914697828747"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNet(32,3).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train_one_epoch(model, loss_fn, optimizer, training_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_hidden_layers, hidden_layer_size, optimizer, device, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyNet(hidden_layer_size, num_hidden_layers).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, training_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(validation_loader.dataset)\n",
    "        vacc = vcorrect / len(validation_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Best parameters:\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'SGD'}\n",
      "Best accuracy: tensor(0.8494, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define different layer configurations\n",
    "num_hidden_layers_list = range(4)\n",
    "hidden_layer_sizes = [32,64,128,256]\n",
    "optimizers= [\n",
    "    \"SGD\",\n",
    "    \"Adam\"\n",
    "]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "# Train models with different configurations\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model(num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }\n",
    "                \n",
    "print(\"Best parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  35\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'SGD'}\n",
      "Best accuracy: tensor(0.8494, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_params_FF= best_params\n",
    "best_acc_FF = best_accuracy\n",
    "best_epochs_num_FF = best_epochs_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parameter normalized to the function for future usings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_1(num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyNet(hidden_layer_size, num_hidden_layers).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_norm\n",
    "        V_loader = validation_loader_norm\n",
    "    else:\n",
    "        T_loader = training_loader\n",
    "        V_loader = validation_loader\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model_1(num_hidden_layers, hidden_layer_size, optimizer, device, True)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  18\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'Adam'}\n",
      "Best accuracy: tensor(0.8519, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_FF_n = best_accuracy\n",
    "best_epochs_num_FF_n = best_epochs_num\n",
    "best_params_FF_n = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try applying Dropout regularization method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet_drop(nn.Module):\n",
    "        def __init__(self,hidden_layer_size, num_hidden_layers):\n",
    "            super(MyNet_drop, self).__init__()\n",
    "            self.num_hidden_layers = num_hidden_layers\n",
    "            self.layers = nn.ModuleList()\n",
    "            self.dropout_in = nn.Dropout( p = 0.1)\n",
    "            self.dropout_h = nn.Dropout( p = 0.5)\n",
    "            #input layer\n",
    "            self.layers.append(nn.Linear(1024, hidden_layer_size))\n",
    "            # hidden layers\n",
    "            for _ in range(num_hidden_layers):\n",
    "                self.layers.append(nn.Linear(hidden_layer_size, hidden_layer_size))\n",
    "            #output layer\n",
    "            self.layers.append(nn.Linear(hidden_layer_size, 10))\n",
    "            # for i in range (1,self.num_hidden_layers):\n",
    "            #     print(self.layers[i])\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.layers[0](x))\n",
    "            x = self.dropout_in(x)\n",
    "            for i in range (1,self.num_hidden_layers+1):\n",
    "                x = F.relu(self.layers[i](x))\n",
    "                x = self.dropout_h(x)\n",
    "            x = self.layers[self.num_hidden_layers+1](x)\n",
    "            return x\n",
    "\n",
    "# model = MyNet_drop(32 , 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_w_dr(num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyNet_drop(hidden_layer_size, num_hidden_layers).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_norm\n",
    "        V_loader = validation_loader_norm\n",
    "    else:\n",
    "        T_loader = training_loader\n",
    "        V_loader = validation_loader\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model_w_dr(num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  60\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'SGD'}\n",
      "Best accuracy: tensor(0.8347, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_FF_Dr = best_accuracy\n",
    "best_epochs_num_FF_Dr = best_epochs_num\n",
    "best_params_FF_Dr = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see using dropout didn't significantly improve the baasic FF model but also is worse than basic model with normalized data\n",
    "\n",
    "now try applying dropout method for normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model_w_dr(num_hidden_layers, hidden_layer_size, optimizer, device, True)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  70\n",
      "{'num_hidden_layers': 0, 'hidden_layer_size': 256, 'optimizer': 'Adam'}\n",
      "Best accuracy: tensor(0.8442, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_FF_Dr_n = best_accuracy\n",
    "best_epochs_num_FF_Dr_n = best_epochs_num\n",
    "best_params_FF_Dr_n = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try dropout + L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_lreg(model, loss_fn, optimizer, training_loader, device, l_alpha = 0.1):\n",
    "    running_cum_loss = 0.\n",
    "\n",
    "    # tqdm is used for nice progress visualisation\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # compute the penalization\n",
    "        l_reg = torch.tensor(0.).to(device)\n",
    "        l_reg += torch.linalg.vector_norm(model.layers[model.num_hidden_layers+1].weight.flatten(),1)\n",
    "        \n",
    "        loss = loss + l_alpha*l_reg.to(device)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        last_mean_loss = loss.item()\n",
    "        running_cum_loss += last_mean_loss * inputs.shape[0]\n",
    "            \n",
    "    # Return of the average over the whole training set\n",
    "    return running_cum_loss / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_w_dr_L1(num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyNet_drop(hidden_layer_size, num_hidden_layers).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_norm\n",
    "        V_loader = validation_loader_norm\n",
    "    else:\n",
    "        T_loader = training_loader\n",
    "        V_loader = validation_loader\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch_lreg(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model_w_dr_L1(num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  28\n",
      "{'num_hidden_layers': 1, 'hidden_layer_size': 256, 'optimizer': 'SGD'}\n",
      "Best accuracy: tensor(0.8275, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_FF_Dr_R1 = best_accuracy\n",
    "best_epochs_num_FF_Dr_R1 = best_epochs_num\n",
    "best_params_FF_Dr_R1 = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_hidden_layers in num_hidden_layers_list:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            print(f\"Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "            accuracy, best_epochs_num = train_model_w_dr_L1(num_hidden_layers, hidden_layer_size, optimizer, device, True)\n",
    "             # Check if current configuration has better accuracy\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {\n",
    "                    \"num_hidden_layers\": num_hidden_layers,\n",
    "                    \"hidden_layer_size\": hidden_layer_size,\n",
    "                    \"optimizer\": optimizer\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  50\n",
      "{'num_hidden_layers': 1, 'hidden_layer_size': 256, 'optimizer': 'Adam'}\n",
      "Best accuracy: tensor(0.8414, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_FF_Dr_R1_n = best_accuracy\n",
    "best_epochs_num_FF_Dr_R1_n = best_epochs_num\n",
    "best_params_FF_Dr_R1_n = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, neither dropout nor dropout + R1 improved the accuracy. Simple FF model trained on normalized data seems to have the best result.\n",
    "\n",
    "A convolutional neural network should provide us with better accuracy, as these networks are primarily used for working with images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first reshape flattened image vektor to 32*32 matrix\n",
    "\n",
    "\n",
    "def reshape_dataset(dataset):\n",
    "    reshaped_dataset = []\n",
    "    for data, label in dataset:\n",
    "        # Reshape data tensor to [32, 32]\n",
    "        reshaped_data = torch.reshape(data, (32, 32)).to(device)\n",
    "        # Add a singleton dimension for the channel\n",
    "        reshaped_data = reshaped_data.unsqueeze(0)\n",
    "        # Reshape label tensor to [1]\n",
    "        reshaped_dataset.append((reshaped_data, label))\n",
    "    return reshaped_dataset\n",
    "\n",
    "\n",
    "# Create reshaped datasets\n",
    "train_data_reshaped = reshape_dataset(train_data)\n",
    "val_data_reshaped = reshape_dataset(val_data)\n",
    "test_data_reshaped = reshape_dataset(test_data)\n",
    "train_data_reshaped_norm = reshape_dataset(train_data_norm)\n",
    "val_data_reshaped_norm = reshape_dataset(val_data_norm)\n",
    "test_data_reshaped_norm = reshape_dataset(test_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#show it:\n",
    "print(train_data_reshaped[0][0].shape)\n",
    "#done\n",
    "\n",
    "training_loader_reshaped = torch.utils.data.DataLoader(train_data_reshaped, batch_size=32, shuffle=True)\n",
    "validation_loader_reshaped = torch.utils.data.DataLoader(val_data_reshaped, batch_size=128, shuffle=False)\n",
    "test_loader_reshaped = torch.utils.data.DataLoader(test_data_reshaped, batch_size=128, shuffle=False)\n",
    "training_loader_reshaped_norm = torch.utils.data.DataLoader(train_data_reshaped_norm, batch_size=32, shuffle=True)\n",
    "validation_loader_reshaped_norm = torch.utils.data.DataLoader(val_data_reshaped_norm, batch_size=128, shuffle=False)\n",
    "test_loader_reshaped_norm = torch.utils.data.DataLoader(test_data_reshaped_norm, batch_size=128, shuffle=False)\n",
    "\n",
    "# dataiter_reshaped = iter(training_loader_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "dataiter_reshaped = iter(training_loader_reshaped)\n",
    "images, labels = next(dataiter_reshaped)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32]) torch.Size([32, 10]) tensor(2, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_conv_layers, num_hidden_layers, hidden_layer_size, kernel_size=2):\n",
    "        super(MyCNN, self).__init__()\n",
    "        \n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        width = 32\n",
    "        input_size = width\n",
    "        \n",
    "        # Add convolutional layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 1 # for first layer\n",
    "        for _ in range(num_conv_layers):\n",
    "            conv_layer = nn.Conv2d(in_channels = in_channels, out_channels = 32, kernel_size = 3)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            in_channels = 32\n",
    "            input_size = int((input_size - 3 + 1)/2)\n",
    "            \n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size = kernel_size, stride=2)\n",
    "        input_size = 32 * input_size * input_size\n",
    "        for _ in range(num_hidden_layers):\n",
    "            hidden_layer = nn.Linear(input_size, hidden_layer_size)\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "            input_size = hidden_layer_size\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fco = nn.Linear(input_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         # Apply convolutional layers\n",
    "        for conv_layer in self.conv_layers:\n",
    "            x = F.relu(conv_layer(x))\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        \n",
    "        # Apply hidden layers\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = F.relu(hidden_layer(x))\n",
    "        \n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyCNN(3,2,32,2).to(device)\n",
    "outputs = model(images)\n",
    "print(images.shape, outputs.shape, labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_CNN(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyCNN(num_conv_layers, num_hidden_layers, hidden_layer_size).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_reshaped_norm\n",
    "        V_loader = validation_loader_reshaped_norm\n",
    "    else:\n",
    "        T_loader = training_loader_reshaped\n",
    "        V_loader = validation_loader_reshaped\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "num_conv_layers_list = range(1,4)\n",
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_conv_layers in num_conv_layers_list:\n",
    "        for num_hidden_layers in num_hidden_layers_list:\n",
    "            for hidden_layer_size in hidden_layer_sizes:\n",
    "                print(f\"Conv_layers: {num_conv_layers}, Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "                accuracy, best_epochs_num = train_model_CNN(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "                # Check if current configuration has better accuracy\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\n",
    "                            \"num_hidden_layers\": num_hidden_layers,\n",
    "                            \"hidden_layer_size\": hidden_layer_size,\n",
    "                            \"optimizer\": optimizer,\n",
    "                            \"num_conv_layer\": num_conv_layer\n",
    "                            \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  32\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'SGD', 'num_conv_layer': 1}\n",
      "Best accuracy: tensor(0.8862, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_CNN = best_accuracy\n",
    "best_epochs_num_CNN = best_epochs_num\n",
    "best_params_CNN = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_layers: 1, Hidden Layers: 3 , Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3 , Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3 , Hidden Layer Size: 256, Optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "# I made a typo with a num_conv layer parameter and also it didn't save best_number_epochs so I'll find it here:\n",
    "best_epochs_num_CNN = 0\n",
    "num_conv_layers_list = range(1,4)\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for num_conv_layers in num_conv_layers_list:\n",
    "    print(f\"Conv_layers: {num_conv_layers}, Hidden Layers: 3 , Hidden Layer Size: 256, Optimizer: SGD\")\n",
    "    accuracy, epochs_num = train_model_CNN(num_conv_layers, 3, 256, \"SGD\", device)\n",
    "    # Check if current configuration has better accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_epochs_num = epochs_num\n",
    "        best_accuracy = accuracy\n",
    "        best_params = {\n",
    "                            \"num_hidden_layers\": num_hidden_layers,\n",
    "                            \"hidden_layer_size\": hidden_layer_size,\n",
    "                            \"optimizer\": optimizer,\n",
    "                            \"num_conv_layer\": num_conv_layers\n",
    "                            \n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  58\n",
      "{'num_hidden_layers': 0, 'hidden_layer_size': 32, 'optimizer': 'SGD', 'num_conv_layer': 2}\n",
      "Best accuracy: tensor(0.8841, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_CNN = best_accuracy\n",
    "best_epochs_num_CNN = best_epochs_num\n",
    "best_params_CNN = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see CNN improved accuracy significantly  to ~0.885 accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With dropout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout to the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32]) torch.Size([32, 10]) tensor(2, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class MyCNN_w_dr(nn.Module):\n",
    "    def __init__(self, num_conv_layers, num_hidden_layers, hidden_layer_size, kernel_size=2):\n",
    "        super(MyCNN_w_dr, self).__init__()\n",
    "        \n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.conv_drop = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        width = 32\n",
    "        input_size = width\n",
    "        \n",
    "        # Add convolutional layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        in_channels = 1 # for first layer\n",
    "        for _ in range(num_conv_layers):\n",
    "            conv_layer = nn.Conv2d(in_channels = in_channels, out_channels = 32, kernel_size = 3)\n",
    "            self.conv_layers.append(conv_layer)\n",
    "            in_channels = 32\n",
    "            input_size = int((input_size - 3 + 1)/2)\n",
    "            \n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size = kernel_size, stride=2)\n",
    "        input_size = 32 * input_size * input_size\n",
    "        for _ in range(num_hidden_layers):\n",
    "            hidden_layer = nn.Linear(input_size, hidden_layer_size)\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "            input_size = hidden_layer_size\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fco = nn.Linear(input_size, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         # Apply convolutional layers\n",
    "        for i, conv_layer in enumerate(self.conv_layers):\n",
    "            x = F.relu(conv_layer(x))\n",
    "            x = self.pool(x)\n",
    "            if i == 0:\n",
    "                x = self.conv_drop(x)\n",
    "        \n",
    "        # Flatten the output\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        \n",
    "        # Apply hidden layers\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = F.relu(hidden_layer(x))\n",
    "        \n",
    "        x = self.fco(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyCNN_w_dr(3,2,32,2).to(device)\n",
    "outputs = model(images)\n",
    "print(images.shape, outputs.shape, labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_CNN_w_dr(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyCNN_w_dr(num_conv_layers, num_hidden_layers, hidden_layer_size).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_reshaped_norm\n",
    "        V_loader = validation_loader_reshaped_norm\n",
    "    else:\n",
    "        T_loader = training_loader_reshaped\n",
    "        V_loader = validation_loader_reshaped\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train and find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "num_conv_layers_list = range(1,4)\n",
    "num_hidden_layers_list = range(4)\n",
    "hidden_layer_sizes = [32,64,128,256]\n",
    "optimizers= [\n",
    "    \"SGD\",\n",
    "    \"Adam\"\n",
    "]\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_conv_layers in num_conv_layers_list:\n",
    "        for num_hidden_layers in num_hidden_layers_list:\n",
    "            for hidden_layer_size in hidden_layer_sizes:\n",
    "                print(f\"Conv_layers: {num_conv_layers}, Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "                accuracy, epochs_num = train_model_CNN_w_dr(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "                # Check if current configuration has better accuracy\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_epochs_num =epochs_num\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\n",
    "                            \"num_hidden_layers\": num_hidden_layers,\n",
    "                            \"hidden_layer_size\": hidden_layer_size,\n",
    "                            \"optimizer\": optimizer,\n",
    "                            \"num_conv_layer\": num_conv_layers\n",
    "                            \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  28\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 256, 'optimizer': 'SGD', 'num_conv_layer': 2}\n",
      "Best accuracy: tensor(0.8853, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_CNN_w_dr = best_accuracy\n",
    "best_epochs_num_CNN_w_dr = best_epochs_num\n",
    "best_params_CNN_w_dr = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout +  L1 regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch_lreg_CNN(model, loss_fn, optimizer, training_loader, device, l_alpha = 0.1):\n",
    "    running_cum_loss = 0.\n",
    "\n",
    "    # tqdm is used for nice progress visualisation\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        # compute the penalization\n",
    "        l_reg = torch.tensor(0.).to(device)\n",
    "        l_reg += torch.linalg.vector_norm(model.fco.weight.flatten(),1)\n",
    "        \n",
    "        loss = loss + l_alpha*l_reg.to(device)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        last_mean_loss = loss.item()\n",
    "        running_cum_loss += last_mean_loss * inputs.shape[0]\n",
    "            \n",
    "    # Return of the average over the whole training set\n",
    "    return running_cum_loss / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_CNN_w_dr_L1(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device, normalized=False, EPOCHS=1000, lr=0.001, early_stop_epochs=20):\n",
    "    model = MyCNN_w_dr(num_conv_layers, num_hidden_layers, hidden_layer_size).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    if optimizer == \"Adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    best_vacc = 0.0  # Best validation accuracy\n",
    "    epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "    best_epochs_num = 0 \n",
    "    if normalized:\n",
    "        T_loader = training_loader_reshaped_norm\n",
    "        V_loader = validation_loader_reshaped_norm\n",
    "    else:\n",
    "        T_loader = training_loader_reshaped\n",
    "        V_loader = validation_loader_reshaped\n",
    "    for epoch in range(EPOCHS):\n",
    "        #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "        # One training step\n",
    "        avg_loss = train_one_epoch_lreg_CNN(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "        # Validation performance\n",
    "        running_cum_vloss = 0.0\n",
    "        vcorrect = 0\n",
    "        for i, vdata in enumerate(V_loader):\n",
    "            vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "            with torch.no_grad():\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "        # Get average loss and accuracy\n",
    "        avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "        vacc = vcorrect / len(V_loader.dataset)\n",
    "        \n",
    "        #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "        # Check if validation accuracy improved\n",
    "        if vacc > best_vacc:\n",
    "            best_vacc = vacc\n",
    "            best_epochs_num = epoch\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break\n",
    "\n",
    "    #print(\"Training finished. Best accuracy was: \", best_vacc)\n",
    "    return best_vacc,best_epochs_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: SGD\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: SGD\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 1, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 2, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 0, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 1, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 2, Hidden Layer Size: 256, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 32, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 64, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 128, Optimizer: Adam\n",
      "Conv_layers: 3, Hidden Layers: 3, Hidden Layer Size: 256, Optimizer: Adam\n"
     ]
    }
   ],
   "source": [
    "num_conv_layers_list = range(1,4)\n",
    "best_accuracy = 0.0\n",
    "best_epochs_num = 0\n",
    "best_params = None\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for num_conv_layers in num_conv_layers_list:\n",
    "        for num_hidden_layers in num_hidden_layers_list:\n",
    "            for hidden_layer_size in hidden_layer_sizes:\n",
    "                print(f\"Conv_layers: {num_conv_layers}, Hidden Layers: {num_hidden_layers}, Hidden Layer Size: {hidden_layer_size}, Optimizer: {optimizer}\")\n",
    "                accuracy, epochs_num = train_model_CNN_w_dr_L1(num_conv_layers, num_hidden_layers, hidden_layer_size, optimizer, device)\n",
    "                # Check if current configuration has better accuracy\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_epochs_num = epochs_num\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\n",
    "                            \"num_hidden_layers\": num_hidden_layers,\n",
    "                            \"hidden_layer_size\": hidden_layer_size,\n",
    "                            \"optimizer\": optimizer,\n",
    "                            \"num_conv_layer\": num_conv_layers\n",
    "                            \n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with number of epochs:  12\n",
      "{'num_hidden_layers': 3, 'hidden_layer_size': 128, 'optimizer': 'Adam', 'num_conv_layer': 2}\n",
      "Best accuracy: tensor(0.8890, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters with number of epochs: \", best_epochs_num)\n",
    "print(best_params)\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "#save accuracy, parameters and number of epochs\n",
    "best_accuracy_CNN_w_dr_L1 = best_accuracy\n",
    "best_epochs_num_CNN_w_dr_L1 = best_epochs_num\n",
    "best_params_CNN_w_dr_L1 = best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see CNN with dropout and L1 regularization has the best accuracy by far. Train a final model using given parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_layers = 3\n",
    "num_conv_layers =2\n",
    "hidden_layer_size =128\n",
    "EPOCHS = 1000\n",
    "early_stop_epochs = 20\n",
    "\n",
    "final_model = MyCNN_w_dr(num_conv_layers, num_hidden_layers, hidden_layer_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "best_vacc = 0.0  # Best validation accuracy\n",
    "epochs_without_improvement = 0  # Count of epochs without improvement\n",
    "best_epochs_num = 0 \n",
    "T_loader = training_loader_reshaped\n",
    "V_loader = validation_loader_reshaped\n",
    "for epoch in range(EPOCHS):\n",
    "    #print('EPOCH {}:'.format(epoch + 1))\n",
    "        \n",
    "    # One training step\n",
    "    avg_loss = train_one_epoch_lreg_CNN(model, loss_fn, optimizer, T_loader, device)\n",
    "        \n",
    "    # Validation performance\n",
    "    running_cum_vloss = 0.0\n",
    "    vcorrect = 0\n",
    "    for i, vdata in enumerate(V_loader):\n",
    "        vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)  # Move validation data to device\n",
    "        with torch.no_grad():\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_cum_vloss += vloss * vinputs.shape[0]\n",
    "            # Count the correctly classified samples\n",
    "            vcorrect += (voutputs.argmax(1) == vlabels).float().sum()\n",
    "        \n",
    "    # Get average loss and accuracy\n",
    "    avg_vloss = running_cum_vloss / len(V_loader.dataset)\n",
    "    vacc = vcorrect / len(V_loader.dataset)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    #print(f\"TRAIN loss: {avg_loss:.3f}, VALIDATION loss: {avg_vloss:.3f}, accuracy: {vacc:.3f}\")\n",
    "        \n",
    "    # Check if validation accuracy improved\n",
    "    if vacc > best_vacc:\n",
    "        best_vacc = vacc\n",
    "        best_epochs_num = epoch\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "        # Check for early stopping\n",
    "    if epochs_without_improvement >= early_stop_epochs:\n",
    "            #print(f\"Validation accuracy did not improve for {early_stop_epochs} epochs. Stopping training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find an approximate accuracy on new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10500,)\n",
      "Test accuracy: 0.8740952380952381\n",
      "[[ 863    0   14   39    8    2  139    0   11    0]\n",
      " [   3 1016    2   17    1    0    4    0    1    0]\n",
      " [  22    1  873   12   65    0   63    0    8    0]\n",
      " [  21    9   10  980   19    0   40    0    1    1]\n",
      " [   3    6  100   59  829    0  100    0    5    0]\n",
      " [   0    1    0    2    0  987    2   32    5   11]\n",
      " [ 128    4   75   37   53    0  736    0    9    2]\n",
      " [   1    0    0    0    0   37    2  950    2   20]\n",
      " [   4    1    4    4    5    3   14    4  988    2]\n",
      " [   0    0    0    2    0   10    0   60    0  956]]\n"
     ]
    }
   ],
   "source": [
    "final_model.eval() \n",
    "test_predictions = np.zeros(len(test_data))\n",
    "test_y = np.zeros(len(test_data))\n",
    "print(test_predictions.shape)\n",
    "ii = 0\n",
    "for i, data in enumerate(test_loader_reshaped):\n",
    "    Tinputs, Tlabels = data[0].to(device), data[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        Toutputs = model(Tinputs)\n",
    "        Tloss = loss_fn(Toutputs, Tlabels)\n",
    "    test_predictions[ii:(ii + Tinputs.shape[0])] = Toutputs.argmax(1).cpu().numpy()\n",
    "    test_y[ii:(ii + Tinputs.shape[0])] = Tlabels.cpu().numpy()\n",
    "    ii += Tinputs.shape[0]\n",
    "    \n",
    "print(f\"Test accuracy: {accuracy_score(test_y, test_predictions)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(test_y, test_predictions)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from evaluate.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  pix1  pix2  pix3  pix4  pix5  pix6  pix7  pix8  pix9  ...  \\\n",
      "0          0     0     0     0     0     0     0     0     0     0  ...   \n",
      "1          1     0     0     0     0     0     0     0     0     0  ...   \n",
      "2          2     0     0     0     0     0     0     0     0     0  ...   \n",
      "3          3     2     2     2     2     2     2     2     2     2  ...   \n",
      "4          4     0     0     0     0     0     0     0     0     0  ...   \n",
      "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "17495  17495     2     2     2     2     2     2     2     2     2  ...   \n",
      "17496  17496     0     0     0     0     0     0     0     0     0  ...   \n",
      "17497  17497     0     0     0     0     0     0     0     0     0  ...   \n",
      "17498  17498     0     0     0     0     0     0     0     0     0  ...   \n",
      "17499  17499     0     0     0     0     0     0     0     0     0  ...   \n",
      "\n",
      "       pix1015  pix1016  pix1017  pix1018  pix1019  pix1020  pix1021  pix1022  \\\n",
      "0            0        0        0        0        0        0        0        0   \n",
      "1            0        0        0        0        0        0        0        0   \n",
      "2            0        0        0        0        0        0        0        0   \n",
      "3            2        2        2        2        2        2        2        2   \n",
      "4            0        0        0        0        0        0        0        0   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "17495        2        2        2        2        2        2        2        2   \n",
      "17496        0        0        0        0        0        0        0        0   \n",
      "17497        0        0        0        0        0        0        0        0   \n",
      "17498        0        0        0        0        0        0        0        0   \n",
      "17499        0        0        0        0        0        0        0        0   \n",
      "\n",
      "       pix1023  pix1024  \n",
      "0            0        0  \n",
      "1            0        0  \n",
      "2            0        0  \n",
      "3            2        2  \n",
      "4            0        0  \n",
      "...        ...      ...  \n",
      "17495        2        2  \n",
      "17496        0        0  \n",
      "17497        0        0  \n",
      "17498        0        0  \n",
      "17499        0        0  \n",
      "\n",
      "[17500 rows x 1025 columns]\n"
     ]
    }
   ],
   "source": [
    "ev = pd.read_csv('evaluate.csv')\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17500, 1024])\n"
     ]
    }
   ],
   "source": [
    "ev_Xdata = ev.drop('ID', axis = 1)\n",
    "ev_Xdata_tensor = torch.tensor(ev_Xdata.values, dtype=torch.float, device=device)\n",
    "print(ev_Xdata_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata_reshaped  = []\n",
    "for data in ev_Xdata_tensor:\n",
    "    # Reshape data tensor to [32, 32]\n",
    "    reshaped_data = torch.reshape(data, (32, 32)).to(device)\n",
    "    # Add a singleton dimension for the channel\n",
    "    reshaped_data = reshaped_data.unsqueeze(0)\n",
    "    Xdata_reshaped.append(reshaped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(Xdata_reshaped[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "Xdata_loader = torch.utils.data.DataLoader(Xdata_reshaped, batch_size=32, shuffle=False)\n",
    "dataiter_reshaped = iter(Xdata_loader)\n",
    "images = next(dataiter_reshaped)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500,)\n"
     ]
    }
   ],
   "source": [
    "ev_predictions = np.zeros(len(Xdata_reshaped))\n",
    "ii = 0\n",
    "print(ev_predictions.shape)\n",
    "for i, data in enumerate(Xdata_loader):\n",
    "    EVinputs = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        EVoutputs = model(EVinputs)\n",
    "    ev_predictions[ii:(ii + EVinputs.shape[0])] = EVoutputs.argmax(1).cpu().numpy()\n",
    "    ii += EVinputs.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 4. 1. ... 7. 3. 5.]\n"
     ]
    }
   ],
   "source": [
    "print(ev_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Craete a new df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17495</th>\n",
       "      <td>17495</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>17496</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>17497</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>17498</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>17499</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  label\n",
       "0          0    9.0\n",
       "1          1    4.0\n",
       "2          2    1.0\n",
       "3          3    7.0\n",
       "4          4    1.0\n",
       "...      ...    ...\n",
       "17495  17495    6.0\n",
       "17496  17496    7.0\n",
       "17497  17497    7.0\n",
       "17498  17498    3.0\n",
       "17499  17499    5.0\n",
       "\n",
       "[17500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results =  pd.DataFrame({'ID': ev.ID, 'label': ev_predictions})\n",
    "display(results)\n",
    "results.to_csv('results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
